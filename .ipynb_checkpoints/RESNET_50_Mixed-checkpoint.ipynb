{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lab\\AppData\\Local\\Continuum\\anaconda3\\envs\\mxnet-gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys, cv2, time\n",
    "import matplotlib.pyplot as plt\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, init, autograd, nd, image\n",
    "from mxnet.gluon import data as gdata, utils as gutils, nn, loss as gloss\n",
    "from mxnet.gluon.data.vision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from ipywidgets import interact, IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_folder = 'E:/Guan-Ming/Deep_ML/all_data_resize/'\n",
    "# output_folder = 'E:/Guan-Ming/Deep_ML/all_data_final_transposed/'\n",
    "# test_data_folder = 'E:/Guan-Ming/Deep_ML/test_data_resize/'\n",
    "# extra_validation_target_folder = 'E:/Guan-Ming/Deep_ML/extra_validation_data_resize/'\n",
    "\n",
    "output_folder = 'Train_Data/'\n",
    "test_data_folder = 'Test_Data/'\n",
    "extra_validation_target_folder = 'Extra_Validation_Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum check pass!\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(output_folder)\n",
    "total_data = len(files)\n",
    "data_x = nd.zeros((total_data, 256, 256, 3)).astype(np.uint8)\n",
    "data_y = nd.zeros(total_data)\n",
    "total_num = 0\n",
    "\n",
    "for index, f in enumerate(files):\n",
    "    data_x[index] = image.imread(output_folder+f)\n",
    "    label = f.split('_',1)[0]\n",
    "    if label == '0':\n",
    "        data_y[index] = 0\n",
    "        total_num += 1\n",
    "    elif label == '1':\n",
    "        data_y[index] = 1\n",
    "        total_num += 1\n",
    "    elif label == '2':\n",
    "        data_y[index] = 2\n",
    "        total_num += 1\n",
    "    elif label == '3':\n",
    "        data_y[index] = 3\n",
    "        total_num += 1\n",
    "    elif label == '4':\n",
    "        data_y[index] = 4\n",
    "        total_num += 1\n",
    "    elif label == '5':\n",
    "        data_y[index] = 5\n",
    "        total_num += 1\n",
    "    else:\n",
    "        raise RuntimeError('Cannot label training data!')\n",
    "\n",
    "if total_num == total_data:\n",
    "    print(\"Sum check pass!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum check pass!\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(test_data_folder)\n",
    "total_test_data = len(files)\n",
    "test_data_x = nd.zeros((total_test_data, 256, 256, 3)).astype(np.uint8)\n",
    "test_data_y = nd.zeros(total_test_data)\n",
    "total_num = 0\n",
    "\n",
    "for index in range(total_test_data):\n",
    "    f = files[index]\n",
    "    test_data_x[index] = image.imread(test_data_folder+f)\n",
    "    label = f.split('_', 1)[0]\n",
    "    if label == '0':\n",
    "        test_data_y[index] = 0\n",
    "        total_num += 1\n",
    "    elif label == '1':\n",
    "        test_data_y[index] = 1\n",
    "        total_num += 1\n",
    "    elif label == '2':\n",
    "        test_data_y[index] = 2\n",
    "        total_num += 1\n",
    "    elif label == '3':\n",
    "        test_data_y[index] = 3\n",
    "        total_num += 1\n",
    "    elif label == '4':\n",
    "        test_data_y[index] = 4\n",
    "        total_num += 1\n",
    "    elif label == '5':\n",
    "        test_data_y[index] = 5\n",
    "        total_num += 1\n",
    "    else:\n",
    "        raise RuntimeError('Cannot label testation data!')\n",
    "        \n",
    "if total_num == total_test_data:\n",
    "    print(\"Sum check pass!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Extra Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum check pass!\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(extra_validation_target_folder)\n",
    "total_extra_validation_data = len(files)\n",
    "extra_validation_data_x = nd.zeros((total_extra_validation_data, 256, 256, 3)).astype(np.uint8)\n",
    "extra_validation_data_y = nd.zeros(total_extra_validation_data)\n",
    "total_num = 0\n",
    "\n",
    "for index, f in enumerate(files):\n",
    "    extra_validation_data_x[index] = image.imread(extra_validation_target_folder+f)\n",
    "\n",
    "    label = f.split('_',1)[0]\n",
    "    if label =='0':\n",
    "        extra_validation_data_y[index] = 0\n",
    "        total_num += 1\n",
    "    elif label =='1':\n",
    "        extra_validation_data_y[index] = 1\n",
    "        total_num += 1\n",
    "    elif label =='2':\n",
    "        extra_validation_data_y[index] = 2\n",
    "        total_num += 1\n",
    "    elif label =='3':\n",
    "        extra_validation_data_y[index] = 3\n",
    "        total_num += 1\n",
    "    elif label =='4':\n",
    "        extra_validation_data_y[index] = 4\n",
    "        total_num += 1\n",
    "    elif label =='5':\n",
    "        extra_validation_data_y[index] = 5\n",
    "        total_num += 1\n",
    "    else:\n",
    "        raise RuntimeError('Cannot label training data!')\n",
    "#    break\n",
    "\n",
    "if total_num == total_extra_validation_data:\n",
    "    print(\"Sum check pass!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Valid Spilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = np.arange(total_data)\n",
    "train_size = 0.8\n",
    "np.random.seed = 61387454\n",
    "np.random.shuffle(data_index)\n",
    "train_index = data_index[:np.int32(total_data*train_size)]\n",
    "valid_index = data_index[np.int32(total_data*train_size):]\n",
    "train_data_x = data_x[train_index]\n",
    "train_data_y = data_y[train_index]\n",
    "valid_data_x = data_x[valid_index]\n",
    "valid_data_y = data_y[valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = [0.592143940485608, 0.5347022953513785, 0.4981124834847486]\n",
    "train_std = [0.2880660398985942, 0.2820819880842514, 0.282954693408029]\n",
    "extra_validation_mean = [0.48470740652217936, 0.4379602084974611, 0.37406493007969804]\n",
    "extra_validation_std = [0.2525134266173694, 0.23321502528915997, 0.2119784063910089]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataset = gdata.ArrayDataset(train_data_x, train_data_y)\n",
    "valid_dataset = gdata.ArrayDataset(valid_data_x, valid_data_y)\n",
    "test_dataset = gdata.ArrayDataset(test_data_x, test_data_y)\n",
    "extra_validation_dataset = gdata.ArrayDataset(extra_validation_data_x, extra_validation_data_y)\n",
    "    \n",
    "transformer = []\n",
    "transformer += [gdata.vision.transforms.ToTensor()] # transer the train data from shape (sample, H, W, channel) to (sample, channel, H, W) and rescale to between 0 and 1 \n",
    "transformer += [gdata.vision.transforms.Normalize(train_mean, train_std)]\n",
    "transformer = gdata.vision.transforms.Compose(transformer)\n",
    "num_workers = 0 if sys.platform.startswith('win32') else 4\n",
    "\n",
    "train_iter = gdata.DataLoader(train_dataset.transform_first(transformer), batch_size = batch_size, shuffle=True, num_workers=num_workers)\n",
    "valid_iter = gdata.DataLoader(valid_dataset.transform_first(transformer), batch_size = batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_iter = gdata.DataLoader(test_dataset.transform_first(transformer), batch_size = batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "extra_transformer = []\n",
    "extra_transformer += [gdata.vision.transforms.ToTensor()] # transer the train data from shape (sample, H, W, channel) to (sample, channel, H, W) and rescale to between 0 and 1 \n",
    "extra_transformer += [gdata.vision.transforms.Normalize(extra_validation_mean, extra_validation_std)]\n",
    "extra_transformer = gdata.vision.transforms.Compose(extra_transformer)\n",
    "extra_validation_iter = gdata.DataLoader(extra_validation_dataset.transform_first(extra_transformer), batch_size = batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu():\n",
    "    \"\"\"If GPU is available, return mx.gpu(0); else return mx.cpu().\"\"\"\n",
    "    try:\n",
    "        ctx = mx.gpu()\n",
    "        _ = nd.array([0], ctx=ctx)\n",
    "    except mx.base.MXNetError:\n",
    "        ctx = mx.cpu()\n",
    "    return ctx\n",
    "def evaluate_accuracy(data_iter, net, ctx=[mx.cpu()]):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    acc_sum, n = nd.array([0]), 0\n",
    "    for batch in data_iter:\n",
    "        features, labels, _ = _get_batch(batch, ctx)\n",
    "        for X, y in zip(features, labels):\n",
    "            y = y.astype('float32')\n",
    "            acc_sum += (net(X).argmax(axis=1) == y).sum().copyto(mx.cpu())\n",
    "            n += y.size\n",
    "        acc_sum.wait_to_read()\n",
    "    return acc_sum.asscalar() / n\n",
    "\n",
    "def _get_batch(batch, ctx):\n",
    "    \"\"\"Return features and labels on ctx.\"\"\"\n",
    "    features, labels = batch\n",
    "    if labels.dtype != features.dtype:\n",
    "        labels = labels.astype(features.dtype)\n",
    "    return (gutils.split_and_load(features, ctx),\n",
    "            gutils.split_and_load(labels, ctx), features.shape[0])\n",
    "\n",
    "def train(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs):\n",
    "    \"\"\"Train and evaluate a model with CPU or GPU.\"\"\"\n",
    "    print('training on', ctx)\n",
    "    loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "    average_time = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                y_hat = net(X)            \n",
    "                l = loss(y_hat, y).sum()\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            y = y.astype('float32')\n",
    "            train_l_sum += l.asscalar()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n",
    "            n += y.size\n",
    "        \n",
    "        test_acc = evaluate_accuracy(test_iter, net, ctx)\n",
    "        epoch_time = time.time() - start\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc, epoch_time))\n",
    "        average_time += epoch_time\n",
    "    print('Average time per epoch is %.4f s.'%(average_time/num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = try_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESNET-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual_Deep(nn.Block):\n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1, **kwargs):\n",
    "        super(Residual_Deep, self).__init__(**kwargs) \n",
    "        self.conv1 = nn.Conv2D(num_channels, kernel_size=1, strides=1) # this layer down-sampling the input\n",
    "        self.conv2 = nn.Conv2D(num_channels, kernel_size=3, padding=1, strides=strides)  # the layer doesn't down-sampling the input\n",
    "        self.conv3 = nn.Conv2D(4*num_channels, kernel_size=1, strides=1)\n",
    "        \n",
    "        if use_1x1conv:\n",
    "            self.conv4 = nn.Conv2D(4*num_channels, kernel_size=1, strides=strides)\n",
    "            # to match the dimension of feature map of conv1 + conv2, the strides must be set to be identicla to conv 1\n",
    "        else: \n",
    "            self.conv4 = None \n",
    "            \n",
    "        self.bn1 = nn.BatchNorm() \n",
    "        self.bn2 = nn.BatchNorm()\n",
    "        self.bn3 = nn.BatchNorm()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        Y = nd.relu(self.bn1(self.conv1(X)))\n",
    "        Y = nd.relu(self.bn2(self.conv2(Y)))\n",
    "        Y = self.bn3(self.conv3(Y))\n",
    "        if self.conv4:\n",
    "            X = self.conv4(X)\n",
    "\n",
    "        return nd.relu(Y + X)\n",
    "\n",
    "def resnet_block_Deep(num_channels, num_residuals, first_block=False): \n",
    "    blk = nn.Sequential() \n",
    "    for i in range(num_residuals): \n",
    "        if i == 0 and not first_block:\n",
    "            #net.add(Residual(num_channels, use_1x1conv=True, strides=2))\n",
    "            blk.add(Residual_Deep(num_channels, use_1x1conv=True, strides=2))\n",
    "        else:\n",
    "            #net.add(Residual(num_channels, strides=1))\n",
    "            blk.add(Residual_Deep(num_channels, strides=1))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_output_channels = [32, 64, 128, 128]\n",
    "num_residuals = [3, 4, 6, 3]\n",
    "\n",
    "net_RESNET_DEEP = nn.Sequential() \n",
    "net_RESNET_DEEP.add(nn.Conv2D(4*num_of_output_channels[0], kernel_size=7, strides=2, padding=3),\n",
    "        nn.BatchNorm(), \n",
    "        nn.Activation('relu'),\n",
    "        nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n",
    "\n",
    "for i, num in enumerate(num_of_output_channels):\n",
    "    if i==0:\n",
    "        net_RESNET_DEEP.add(resnet_block_Deep(num, num_residuals[i], first_block=True))\n",
    "    else:\n",
    "        net_RESNET_DEEP.add(resnet_block_Deep(num, num_residuals[i]))\n",
    "    net_RESNET_DEEP.add(nn.Dropout(0.3))\n",
    "\n",
    "net_RESNET_DEEP.add(nn.GlobalAvgPool2D(), nn.Dense(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize or Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net_RESNET_DEEP.load_parameters('Weight_Train_Test_Mixed/RESNET50_DROPOUT_train_data_transposed_2.params', ctx= ctx)\n",
    "#net_RESNET_DEEP.load_parameters('C:/Users/lab/Jupyter_Notebook/Guan-Ming/Midterm_Project/NN_params/train_test_mixed/RESNET50_DROPOUT_train_data_transposed.params', ctx=ctx)\n",
    "net_RESNET_DEEP.initialize(ctx=ctx, init=mx.init.Xavier(rnd_type ='gaussian', factor_type='in', magnitude=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "        Layer (type)                                Output Shape         Param #\n",
      "================================================================================\n",
      "               Input                           (64, 3, 256, 256)               0\n",
      "            Conv2D-1                         (64, 128, 128, 128)           18944\n",
      "         BatchNorm-2                         (64, 128, 128, 128)             512\n",
      "        Activation-3                         (64, 128, 128, 128)               0\n",
      "         MaxPool2D-4                           (64, 128, 64, 64)               0\n",
      "            Conv2D-5                            (64, 32, 64, 64)            4128\n",
      "         BatchNorm-6                            (64, 32, 64, 64)             128\n",
      "            Conv2D-7                            (64, 32, 64, 64)            9248\n",
      "         BatchNorm-8                            (64, 32, 64, 64)             128\n",
      "            Conv2D-9                           (64, 128, 64, 64)            4224\n",
      "        BatchNorm-10                           (64, 128, 64, 64)             512\n",
      "    Residual_Deep-11                           (64, 128, 64, 64)               0\n",
      "           Conv2D-12                            (64, 32, 64, 64)            4128\n",
      "        BatchNorm-13                            (64, 32, 64, 64)             128\n",
      "           Conv2D-14                            (64, 32, 64, 64)            9248\n",
      "        BatchNorm-15                            (64, 32, 64, 64)             128\n",
      "           Conv2D-16                           (64, 128, 64, 64)            4224\n",
      "        BatchNorm-17                           (64, 128, 64, 64)             512\n",
      "    Residual_Deep-18                           (64, 128, 64, 64)               0\n",
      "           Conv2D-19                            (64, 32, 64, 64)            4128\n",
      "        BatchNorm-20                            (64, 32, 64, 64)             128\n",
      "           Conv2D-21                            (64, 32, 64, 64)            9248\n",
      "        BatchNorm-22                            (64, 32, 64, 64)             128\n",
      "           Conv2D-23                           (64, 128, 64, 64)            4224\n",
      "        BatchNorm-24                           (64, 128, 64, 64)             512\n",
      "    Residual_Deep-25                           (64, 128, 64, 64)               0\n",
      "          Dropout-26                           (64, 128, 64, 64)               0\n",
      "           Conv2D-27                            (64, 64, 64, 64)            8256\n",
      "        BatchNorm-28                            (64, 64, 64, 64)             256\n",
      "           Conv2D-29                            (64, 64, 32, 32)           36928\n",
      "        BatchNorm-30                            (64, 64, 32, 32)             256\n",
      "           Conv2D-31                           (64, 256, 32, 32)           16640\n",
      "        BatchNorm-32                           (64, 256, 32, 32)            1024\n",
      "           Conv2D-33                           (64, 256, 32, 32)           33024\n",
      "    Residual_Deep-34                           (64, 256, 32, 32)               0\n",
      "           Conv2D-35                            (64, 64, 32, 32)           16448\n",
      "        BatchNorm-36                            (64, 64, 32, 32)             256\n",
      "           Conv2D-37                            (64, 64, 32, 32)           36928\n",
      "        BatchNorm-38                            (64, 64, 32, 32)             256\n",
      "           Conv2D-39                           (64, 256, 32, 32)           16640\n",
      "        BatchNorm-40                           (64, 256, 32, 32)            1024\n",
      "    Residual_Deep-41                           (64, 256, 32, 32)               0\n",
      "           Conv2D-42                            (64, 64, 32, 32)           16448\n",
      "        BatchNorm-43                            (64, 64, 32, 32)             256\n",
      "           Conv2D-44                            (64, 64, 32, 32)           36928\n",
      "        BatchNorm-45                            (64, 64, 32, 32)             256\n",
      "           Conv2D-46                           (64, 256, 32, 32)           16640\n",
      "        BatchNorm-47                           (64, 256, 32, 32)            1024\n",
      "    Residual_Deep-48                           (64, 256, 32, 32)               0\n",
      "           Conv2D-49                            (64, 64, 32, 32)           16448\n",
      "        BatchNorm-50                            (64, 64, 32, 32)             256\n",
      "           Conv2D-51                            (64, 64, 32, 32)           36928\n",
      "        BatchNorm-52                            (64, 64, 32, 32)             256\n",
      "           Conv2D-53                           (64, 256, 32, 32)           16640\n",
      "        BatchNorm-54                           (64, 256, 32, 32)            1024\n",
      "    Residual_Deep-55                           (64, 256, 32, 32)               0\n",
      "          Dropout-56                           (64, 256, 32, 32)               0\n",
      "           Conv2D-57                           (64, 128, 32, 32)           32896\n",
      "        BatchNorm-58                           (64, 128, 32, 32)             512\n",
      "           Conv2D-59                           (64, 128, 16, 16)          147584\n",
      "        BatchNorm-60                           (64, 128, 16, 16)             512\n",
      "           Conv2D-61                           (64, 512, 16, 16)           66048\n",
      "        BatchNorm-62                           (64, 512, 16, 16)            2048\n",
      "           Conv2D-63                           (64, 512, 16, 16)          131584\n",
      "    Residual_Deep-64                           (64, 512, 16, 16)               0\n",
      "           Conv2D-65                           (64, 128, 16, 16)           65664\n",
      "        BatchNorm-66                           (64, 128, 16, 16)             512\n",
      "           Conv2D-67                           (64, 128, 16, 16)          147584\n",
      "        BatchNorm-68                           (64, 128, 16, 16)             512\n",
      "           Conv2D-69                           (64, 512, 16, 16)           66048\n",
      "        BatchNorm-70                           (64, 512, 16, 16)            2048\n",
      "    Residual_Deep-71                           (64, 512, 16, 16)               0\n",
      "           Conv2D-72                           (64, 128, 16, 16)           65664\n",
      "        BatchNorm-73                           (64, 128, 16, 16)             512\n",
      "           Conv2D-74                           (64, 128, 16, 16)          147584\n",
      "        BatchNorm-75                           (64, 128, 16, 16)             512\n",
      "           Conv2D-76                           (64, 512, 16, 16)           66048\n",
      "        BatchNorm-77                           (64, 512, 16, 16)            2048\n",
      "    Residual_Deep-78                           (64, 512, 16, 16)               0\n",
      "           Conv2D-79                           (64, 128, 16, 16)           65664\n",
      "        BatchNorm-80                           (64, 128, 16, 16)             512\n",
      "           Conv2D-81                           (64, 128, 16, 16)          147584\n",
      "        BatchNorm-82                           (64, 128, 16, 16)             512\n",
      "           Conv2D-83                           (64, 512, 16, 16)           66048\n",
      "        BatchNorm-84                           (64, 512, 16, 16)            2048\n",
      "    Residual_Deep-85                           (64, 512, 16, 16)               0\n",
      "           Conv2D-86                           (64, 128, 16, 16)           65664\n",
      "        BatchNorm-87                           (64, 128, 16, 16)             512\n",
      "           Conv2D-88                           (64, 128, 16, 16)          147584\n",
      "        BatchNorm-89                           (64, 128, 16, 16)             512\n",
      "           Conv2D-90                           (64, 512, 16, 16)           66048\n",
      "        BatchNorm-91                           (64, 512, 16, 16)            2048\n",
      "    Residual_Deep-92                           (64, 512, 16, 16)               0\n",
      "           Conv2D-93                           (64, 128, 16, 16)           65664\n",
      "        BatchNorm-94                           (64, 128, 16, 16)             512\n",
      "           Conv2D-95                           (64, 128, 16, 16)          147584\n",
      "        BatchNorm-96                           (64, 128, 16, 16)             512\n",
      "           Conv2D-97                           (64, 512, 16, 16)           66048\n",
      "        BatchNorm-98                           (64, 512, 16, 16)            2048\n",
      "    Residual_Deep-99                           (64, 512, 16, 16)               0\n",
      "         Dropout-100                           (64, 512, 16, 16)               0\n",
      "          Conv2D-101                           (64, 128, 16, 16)           65664\n",
      "       BatchNorm-102                           (64, 128, 16, 16)             512\n",
      "          Conv2D-103                             (64, 128, 8, 8)          147584\n",
      "       BatchNorm-104                             (64, 128, 8, 8)             512\n",
      "          Conv2D-105                             (64, 512, 8, 8)           66048\n",
      "       BatchNorm-106                             (64, 512, 8, 8)            2048\n",
      "          Conv2D-107                             (64, 512, 8, 8)          262656\n",
      "   Residual_Deep-108                             (64, 512, 8, 8)               0\n",
      "          Conv2D-109                             (64, 128, 8, 8)           65664\n",
      "       BatchNorm-110                             (64, 128, 8, 8)             512\n",
      "          Conv2D-111                             (64, 128, 8, 8)          147584\n",
      "       BatchNorm-112                             (64, 128, 8, 8)             512\n",
      "          Conv2D-113                             (64, 512, 8, 8)           66048\n",
      "       BatchNorm-114                             (64, 512, 8, 8)            2048\n",
      "   Residual_Deep-115                             (64, 512, 8, 8)               0\n",
      "          Conv2D-116                             (64, 128, 8, 8)           65664\n",
      "       BatchNorm-117                             (64, 128, 8, 8)             512\n",
      "          Conv2D-118                             (64, 128, 8, 8)          147584\n",
      "       BatchNorm-119                             (64, 128, 8, 8)             512\n",
      "          Conv2D-120                             (64, 512, 8, 8)           66048\n",
      "       BatchNorm-121                             (64, 512, 8, 8)            2048\n",
      "   Residual_Deep-122                             (64, 512, 8, 8)               0\n",
      "         Dropout-123                             (64, 512, 8, 8)               0\n",
      " GlobalAvgPool2D-124                             (64, 512, 1, 1)               0\n",
      "           Dense-125                                     (64, 6)            3078\n",
      "================================================================================\n",
      "Parameters in forward computation graph, duplicate included\n",
      "   Total params: 3291462\n",
      "   Trainable params: 3273158\n",
      "   Non-trainable params: 18304\n",
      "Shared params in forward computation graph: 0\n",
      "Unique parameters in model: 3291462\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for X,_ in train_iter:\n",
    "    net_RESNET_DEEP.summary(X.as_in_context(ctx))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on gpu(0)\n",
      "epoch 1, loss 0.0932, train acc 0.975, test acc 0.981, time 86.3 sec\n",
      "epoch 2, loss 0.0648, train acc 0.984, test acc 0.983, time 86.1 sec\n",
      "epoch 3, loss 0.0541, train acc 0.988, test acc 0.991, time 85.7 sec\n",
      "epoch 4, loss 0.0484, train acc 0.987, test acc 0.990, time 86.1 sec\n",
      "epoch 5, loss 0.0400, train acc 0.991, test acc 0.988, time 86.6 sec\n",
      "epoch 6, loss 0.0364, train acc 0.991, test acc 0.984, time 86.7 sec\n",
      "epoch 7, loss 0.0377, train acc 0.990, test acc 0.982, time 86.7 sec\n",
      "epoch 8, loss 0.0295, train acc 0.994, test acc 0.996, time 86.9 sec\n",
      "epoch 9, loss 0.0289, train acc 0.994, test acc 0.995, time 87.3 sec\n",
      "epoch 10, loss 0.0228, train acc 0.994, test acc 0.990, time 87.3 sec\n",
      "Average time per epoch is 86.5497 s.\n"
     ]
    }
   ],
   "source": [
    "adam_optimizer = mx.optimizer.Adam(learning_rate=1e-4, beta1=0.9, beta2=0.9)\n",
    "trainer = gluon.Trainer(net_RESNET_DEEP.collect_params(), optimizer=adam_optimizer)\n",
    "train(net_RESNET_DEEP, train_iter, valid_iter, batch_size, trainer, ctx, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Accuracy for Testing Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model is 75.3333 % .\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of model is %.4f %% .'%(100*evaluate_accuracy(test_iter, net_RESNET_DEEP, ctx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Accuracy for Extra Validation Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model is 44.6429 % .\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of model is %.4f %% .'%(100*evaluate_accuracy(extra_validation_iter, net_RESNET_DEEP, ctx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Saving and Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net_RESNET_DEEP.save_parameters('C:/Users/lab/Jupyter_Notebook/Guan-Ming/Midterm_Project/NN_params/train_test_mixed/RESNET50_DROPOUT_train_data_transposed_3.params')\n",
    "#===============================================================\n",
    "# num_of_output_channels = [32, 64, 128, 128]\n",
    "# num_residuals = [3, 4, 6, 3]\n",
    "\n",
    "# net_RESNET_DEEP = nn.Sequential() \n",
    "# net_RESNET_DEEP.add(nn.Conv2D(4*num_of_output_channels[0], kernel_size=7, strides=2, padding=3),\n",
    "#         nn.BatchNorm(), \n",
    "#         nn.Activation('relu'),\n",
    "#         nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n",
    "\n",
    "# for i, num in enumerate(num_of_output_channels):\n",
    "#     if i==0:\n",
    "#         net_RESNET_DEEP.add(resnet_block_Deep(num, num_residuals[i], first_block=True))\n",
    "#     else:\n",
    "#         net_RESNET_DEEP.add(resnet_block_Deep(num, num_residuals[i]))\n",
    "#     net_RESNET_DEEP.add(nn.Dropout(0.3))\n",
    "\n",
    "# net_RESNET_DEEP.add(nn.GlobalAvgPool2D(), nn.Dense(6))\n",
    "#==============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix of Testing Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = np.zeros(total_test_data)\n",
    "count = 0\n",
    "for X, _ in test_iter:\n",
    "    y_pred_test[count:min(count+batch_size, total_test_data)] = net_RESNET_DEEP(X.as_in_context(ctx)).asnumpy().argmax(axis=1)\n",
    "    count += batch_size\n",
    "wrong_index_test = np.argwhere(y_pred_test!=test_data_y.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33  3  3  2  0  9]\n",
      " [ 0 45  4  0  0  1]\n",
      " [ 0  3 42  4  1  0]\n",
      " [ 0  1  1 39  8  1]\n",
      " [ 0  0  8  1 40  1]\n",
      " [ 0  0  5  1  2 42]]\n",
      "\n",
      "\n",
      "Accuracy of 0 is 66.00 %.\n",
      "Accuracy of 1 is 90.00 %.\n",
      "Accuracy of 2 is 84.00 %.\n",
      "Accuracy of 3 is 78.00 %.\n",
      "Accuracy of 4 is 80.00 %.\n",
      "Accuracy of 5 is 84.00 %.\n"
     ]
    }
   ],
   "source": [
    "result = confusion_matrix(test_data_y.asnumpy(), y_pred_test)\n",
    "print(result)\n",
    "print('\\n')\n",
    "for i in range(6):\n",
    "    print(\"Accuracy of %d is %.2f %%.\" %(i, 100*result[i][i]/result[i].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 59 wrong predcition. Slide to see the corresponding image.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6426f448ff8e48eb877484d2ce9f64dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index_selected', max=58), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def PLOT_WRONG_PREDICTION(index_selected):\n",
    "    print(index_selected)\n",
    "    plt.figure(figsize=(3,3), dpi=120)\n",
    "    plt.imshow(test_data_x[wrong_index_test[index_selected]][0].asnumpy().astype(np.uint8))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"NN Recognizes as %d .\\nReal Answer is %d .\" %(y_pred_test[wrong_index_test[index_selected]], test_data_y[wrong_index_test[index_selected]].asscalar()) )\n",
    "    \n",
    "print('Total %d wrong predcition. Slide to see the corresponding image.' %len(wrong_index_test))\n",
    "interact(PLOT_WRONG_PREDICTION, index_selected=IntSlider(value=0, min=0, max=len(wrong_index_test)-1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix of Extra Validation Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_extra_validation = np.zeros(total_extra_validation_data)\n",
    "count = 0\n",
    "for X, _ in extra_validation_iter:\n",
    "    y_pred_extra_validation[count:count+batch_size] = net_RESNET_DEEP(X.as_in_context(ctx))[:total_extra_validation_data].asnumpy().argmax(axis=1)\n",
    "    count += batch_size\n",
    "wrong_index_extra_validation = np.argwhere(y_pred_extra_validation!=extra_validation_data_y.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  0  0  0  0  0]\n",
      " [ 0  4  2  0  0  0]\n",
      " [ 0  0  5  1  0  0]\n",
      " [ 0  1  2 16  5  3]\n",
      " [ 0  0  0  1  3  1]\n",
      " [ 0  0  1  0  2  7]]\n",
      "\n",
      "\n",
      "Accuracy of 0 is 100.00 %.\n",
      "Accuracy of 1 is 66.67 %.\n",
      "Accuracy of 2 is 83.33 %.\n",
      "Accuracy of 3 is 59.26 %.\n",
      "Accuracy of 4 is 60.00 %.\n",
      "Accuracy of 5 is 70.00 %.\n"
     ]
    }
   ],
   "source": [
    "result = confusion_matrix(extra_validation_data_y.asnumpy(), y_pred_extra_validation)\n",
    "print(result)\n",
    "print('\\n')\n",
    "for i in range(6):\n",
    "    print(\"Accuracy of %d is %.2f %%.\" %(i, 100*result[i][i]/result[i].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 19 wrong predcition. Slide to see the corresponding image.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da01a884e2a0469daa774f05df39ce01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index_selected', max=18), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def PLOT_WRONG_PREDICTION(index_selected):\n",
    "    print(index_selected)\n",
    "    plt.figure(figsize=(3,3), dpi=120)\n",
    "    plt.imshow(extra_validation_data_x[wrong_index_extra_validation[index_selected]][0].asnumpy().astype(np.uint8))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"NN Recognizes as %d .\\nReal Answer is %d .\" %(y_pred_extra_validation[wrong_index_extra_validation[index_selected]], extra_validation_data_y[wrong_index_extra_validation[index_selected]].asscalar()) )\n",
    "    \n",
    "print('Total %d wrong predcition. Slide to see the corresponding image.' %len(wrong_index_extra_validation))\n",
    "interact(PLOT_WRONG_PREDICTION, index_selected=IntSlider(value=0, min=0, max=len(wrong_index_extra_validation)-1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
