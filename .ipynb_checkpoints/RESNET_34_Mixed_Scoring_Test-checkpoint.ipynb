{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys, cv2, time\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, init, autograd, nd, image\n",
    "from mxnet.gluon import data as gdata, utils as gutils, nn, loss as gloss\n",
    "from mxnet.gluon.data.vision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gray to RGB is converted by [this site](https://demos.algorithmia.com/colorize-photos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_validation_target_folder = 'Scoring_Validation_Data(Gray_2_RGB)/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum check pass!\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(final_validation_target_folder)\n",
    "total_final_validation_data = len(files)\n",
    "final_validation_data_x = nd.zeros((total_final_validation_data, 256, 256, 3)).astype(np.uint8)\n",
    "final_validation_data_y = nd.zeros(total_final_validation_data)\n",
    "total_num = 0\n",
    "\n",
    "for index, f in enumerate(files):\n",
    "    final_validation_data_x[index] = image.imread(final_validation_target_folder+f)\n",
    "\n",
    "    label = f.split('_',1)[0]\n",
    "    if label =='0':\n",
    "        final_validation_data_y[index] = 0\n",
    "        total_num += 1\n",
    "    elif label =='1':\n",
    "        final_validation_data_y[index] = 1\n",
    "        total_num += 1\n",
    "    elif label =='2':\n",
    "        final_validation_data_y[index] = 2\n",
    "        total_num += 1\n",
    "    elif label =='3':\n",
    "        final_validation_data_y[index] = 3\n",
    "        total_num += 1\n",
    "    elif label =='4':\n",
    "        final_validation_data_y[index] = 4\n",
    "        total_num += 1\n",
    "    elif label =='5':\n",
    "        final_validation_data_y[index] = 5\n",
    "        total_num += 1\n",
    "    else:\n",
    "        raise RuntimeError('Cannot label training data!')\n",
    "#    break\n",
    "\n",
    "if total_num == total_final_validation_data:\n",
    "    print(\"Sum check pass!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = [0.5905187523955868, 0.5332879723913606, 0.49680592040529487]  #over all data\n",
    "train_std = [0.28736647217403904, 0.28094815765222825, 0.2815392173263535]  #over all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 0 if sys.platform.startswith('win32') else 4\n",
    "\n",
    "final_validation_dataset = gdata.ArrayDataset(final_validation_data_x, final_validation_data_y)\n",
    "    \n",
    "transformer = []\n",
    "transformer += [gdata.vision.transforms.ToTensor()] # transer the train data from shape (sample, H, W, channel) to (sample, channel, H, W) and rescale to between 0 and 1 \n",
    "transformer += [gdata.vision.transforms.Normalize(train_mean, train_std)]\n",
    "transformer = gdata.vision.transforms.Compose(transformer)\n",
    "final_validation_iter = gdata.DataLoader(final_validation_dataset.transform_first(transformer), batch_size = batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu():\n",
    "    \"\"\"If GPU is available, return mx.gpu(0); else return mx.cpu().\"\"\"\n",
    "    try:\n",
    "        ctx = mx.gpu()\n",
    "        _ = nd.array([0], ctx=ctx)\n",
    "    except mx.base.MXNetError:\n",
    "        ctx = mx.cpu()\n",
    "    return ctx\n",
    "def evaluate_accuracy(data_iter, net, ctx=[mx.cpu()]):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    acc_sum, n = nd.array([0]), 0\n",
    "    for batch in data_iter:\n",
    "        features, labels, _ = _get_batch(batch, ctx)\n",
    "        for X, y in zip(features, labels):\n",
    "            y = y.astype('float32')\n",
    "            acc_sum += (net(X).argmax(axis=1) == y).sum().copyto(mx.cpu())\n",
    "            n += y.size\n",
    "        acc_sum.wait_to_read()\n",
    "    return acc_sum.asscalar() / n\n",
    "\n",
    "def _get_batch(batch, ctx):\n",
    "    \"\"\"Return features and labels on ctx.\"\"\"\n",
    "    features, labels = batch\n",
    "    if labels.dtype != features.dtype:\n",
    "        labels = labels.astype(features.dtype)\n",
    "    return (gutils.split_and_load(features, ctx),\n",
    "            gutils.split_and_load(labels, ctx), features.shape[0])\n",
    "\n",
    "def train(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs):\n",
    "    \"\"\"Train and evaluate a model with CPU or GPU.\"\"\"\n",
    "    print('training on', ctx)\n",
    "    loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "    average_time = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                y_hat = net(X)            \n",
    "                l = loss(y_hat, y).sum()\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            y = y.astype('float32')\n",
    "            train_l_sum += l.asscalar()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n",
    "            n += y.size\n",
    "        \n",
    "        test_acc = evaluate_accuracy(test_iter, net, ctx)\n",
    "        epoch_time = time.time() - start\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc, epoch_time))\n",
    "        average_time += epoch_time\n",
    "    print('Average time per epoch is %.4f s.'%(average_time/num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = try_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Block):\n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1, **kwargs):\n",
    "        super(Residual, self).__init__(**kwargs) \n",
    "        self.conv1 = nn.Conv2D(num_channels, kernel_size=3, padding=1, strides=strides) # this layer down-sampling the input\n",
    "        self.conv2 = nn.Conv2D(num_channels, kernel_size=3, padding=1)  # the layer doesn't down-sampling the input\n",
    "        \n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2D(num_channels, kernel_size=1, strides=strides)\n",
    "            # to match the dimension of feature map of conv1 + conv2, the strides must be set to be identicla to conv 1\n",
    "        else: \n",
    "            self.conv3 = None \n",
    "            \n",
    "        self.bn1 = nn.BatchNorm() \n",
    "        self.bn2 = nn.BatchNorm()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        Y = nd.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y)) \n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "\n",
    "        return nd.relu(Y + X)\n",
    "    \n",
    "def resnet_block(num_channels, num_residuals, first_block=False): \n",
    "    blk = nn.Sequential() \n",
    "    for i in range(num_residuals): \n",
    "        if i == 0 and not first_block:\n",
    "            #net.add(Residual(num_channels, use_1x1conv=True, strides=2))\n",
    "            blk.add(Residual(num_channels, use_1x1conv=True, strides=2))\n",
    "        else:\n",
    "            #net.add(Residual(num_channels, strides=1))\n",
    "            blk.add(Residual(num_channels, strides=1))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_output_channels = [64, 128, 256, 512]\n",
    "num_residuals = [3, 4, 6, 3]\n",
    "\n",
    "net_RESNET = nn.Sequential() \n",
    "net_RESNET.add(nn.Conv2D(64, kernel_size=7, strides=2, padding=3),\n",
    "        nn.BatchNorm(), \n",
    "        nn.Activation('relu'),\n",
    "        nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n",
    "\n",
    "for i, num in enumerate(num_of_output_channels):\n",
    "    if i==0:\n",
    "        net_RESNET.add(resnet_block(num, num_residuals[i], first_block=True))\n",
    "    else:\n",
    "        net_RESNET.add(resnet_block(num, num_residuals[i]))\n",
    "    net_RESNET.add(nn.Dropout(0.1))\n",
    "\n",
    "net_RESNET.add(nn.GlobalAvgPool2D(), nn.Dense(6))\n",
    "net_RESNET.load_parameters('Weight_Train_Test_Mixed/RESNET34_DROPOUT_train_data_transposed_7_fine_tuned.params', ctx= ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model is 93.8272 % .\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of model is %.4f %% .'%(100*evaluate_accuracy(final_validation_iter, net_RESNET, ctx)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
