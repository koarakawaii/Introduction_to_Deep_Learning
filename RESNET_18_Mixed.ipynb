{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys, cv2, time\n",
    "import matplotlib.pyplot as plt\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, init, autograd, nd, image\n",
    "from mxnet.gluon import data as gdata, utils as gutils, nn, loss as gloss\n",
    "from shutil import copyfile\n",
    "from mxnet.gluon.data.vision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from ipywidgets import interact, IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_folder = 'E:/Guan-Ming/Deep_ML/all_data_resize/'\n",
    "# output_folder = 'E:/Guan-Ming/Deep_ML/all_data_final_transposed/'\n",
    "# test_data_folder = 'E:/Guan-Ming/Deep_ML/test_data_resize/'\n",
    "# extra_validation_target_folder = 'E:/Guan-Ming/Deep_ML/extra_validation_data_resize/'\n",
    "\n",
    "output_folder = 'Train_Data/'\n",
    "test_data_folder = 'Test_Data/'\n",
    "extra_validation_target_folder = 'Extra_Validation_Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum check pass!\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(output_folder)\n",
    "total_data = len(files)\n",
    "data_x = nd.zeros((total_data, 256, 256, 3)).astype(np.uint8)\n",
    "data_y = nd.zeros(total_data)\n",
    "total_num = 0\n",
    "\n",
    "for index, f in enumerate(files):\n",
    "    data_x[index] = image.imread(output_folder+f)\n",
    "    label = f.split('_',1)[0]\n",
    "    if label == '0':\n",
    "        data_y[index] = 0\n",
    "        total_num += 1\n",
    "    elif label == '1':\n",
    "        data_y[index] = 1\n",
    "        total_num += 1\n",
    "    elif label == '2':\n",
    "        data_y[index] = 2\n",
    "        total_num += 1\n",
    "    elif label == '3':\n",
    "        data_y[index] = 3\n",
    "        total_num += 1\n",
    "    elif label == '4':\n",
    "        data_y[index] = 4\n",
    "        total_num += 1\n",
    "    elif label == '5':\n",
    "        data_y[index] = 5\n",
    "        total_num += 1\n",
    "    else:\n",
    "        raise RuntimeError('Cannot label training data!')\n",
    "\n",
    "if total_num == total_data:\n",
    "    print(\"Sum check pass!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum check pass!\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(test_data_folder)\n",
    "total_test_data = len(files)\n",
    "test_data_x = nd.zeros((total_test_data, 256, 256, 3)).astype(np.uint8)\n",
    "test_data_y = nd.zeros(total_test_data)\n",
    "total_num = 0\n",
    "np.random.seed = 123456\n",
    "test_index_order = np.arange(total_test_data)\n",
    "np.random.shuffle(test_index_order)\n",
    "\n",
    "for index, index_shuffled in enumerate(test_index_order):\n",
    "    f = files[index_shuffled]\n",
    "    test_data_x[index] = image.imread(test_data_folder+f)\n",
    "    label = f.split('_', 1)[0]\n",
    "    if label == '0':\n",
    "        test_data_y[index] = 0\n",
    "        total_num += 1\n",
    "    elif label == '1':\n",
    "        test_data_y[index] = 1\n",
    "        total_num += 1\n",
    "    elif label == '2':\n",
    "        test_data_y[index] = 2\n",
    "        total_num += 1\n",
    "    elif label == '3':\n",
    "        test_data_y[index] = 3\n",
    "        total_num += 1\n",
    "    elif label == '4':\n",
    "        test_data_y[index] = 4\n",
    "        total_num += 1\n",
    "    elif label == '5':\n",
    "        test_data_y[index] = 5\n",
    "        total_num += 1\n",
    "    else:\n",
    "        raise RuntimeError('Cannot label testation data!')\n",
    "        \n",
    "if total_num == total_test_data:\n",
    "    print(\"Sum check pass!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Extra Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum check pass!\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(extra_validation_target_folder)\n",
    "total_extra_validation_data = len(files)\n",
    "extra_validation_data_x = nd.zeros((total_extra_validation_data, 256, 256, 3)).astype(np.uint8)\n",
    "extra_validation_data_y = nd.zeros(total_extra_validation_data)\n",
    "total_num = 0\n",
    "\n",
    "for index, f in enumerate(files):\n",
    "    extra_validation_data_x[index] = image.imread(extra_validation_target_folder+f)\n",
    "\n",
    "    label = f.split('_',1)[0]\n",
    "    if label =='0':\n",
    "        extra_validation_data_y[index] = 0\n",
    "        total_num += 1\n",
    "    elif label =='1':\n",
    "        extra_validation_data_y[index] = 1\n",
    "        total_num += 1\n",
    "    elif label =='2':\n",
    "        extra_validation_data_y[index] = 2\n",
    "        total_num += 1\n",
    "    elif label =='3':\n",
    "        extra_validation_data_y[index] = 3\n",
    "        total_num += 1\n",
    "    elif label =='4':\n",
    "        extra_validation_data_y[index] = 4\n",
    "        total_num += 1\n",
    "    elif label =='5':\n",
    "        extra_validation_data_y[index] = 5\n",
    "        total_num += 1\n",
    "    else:\n",
    "        raise RuntimeError('Cannot label training data!')\n",
    "#    break\n",
    "\n",
    "if total_num == total_extra_validation_data:\n",
    "    print(\"Sum check pass!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Valid Spilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = np.arange(total_data)\n",
    "#train_size = 0.65\n",
    "train_size = 0.8\n",
    "np.random.seed = 61387454\n",
    "np.random.shuffle(data_index)\n",
    "train_index = data_index[:np.int32(total_data*train_size)]\n",
    "valid_index = data_index[np.int32(total_data*train_size):]\n",
    "train_data_x = data_x[train_index]\n",
    "train_data_y = data_y[train_index]\n",
    "valid_data_x = data_x[valid_index]\n",
    "valid_data_y = data_y[valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = [0.592143940485608, 0.5347022953513785, 0.4981124834847486]\n",
    "train_std = [0.2880660398985942, 0.2820819880842514, 0.282954693408029]\n",
    "extra_validation_mean = [0.48470740652217936, 0.4379602084974611, 0.37406493007969804]\n",
    "extra_validation_std = [0.2525134266173694, 0.23321502528915997, 0.2119784063910089]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataset = gdata.ArrayDataset(train_data_x, train_data_y)\n",
    "valid_dataset = gdata.ArrayDataset(valid_data_x, valid_data_y)\n",
    "test_dataset = gdata.ArrayDataset(test_data_x, test_data_y)\n",
    "extra_validation_dataset = gdata.ArrayDataset(extra_validation_data_x, extra_validation_data_y)\n",
    "    \n",
    "transformer = []\n",
    "transformer += [gdata.vision.transforms.ToTensor()] # transer the train data from shape (sample, H, W, channel) to (sample, channel, H, W) and rescale to between 0 and 1 \n",
    "transformer += [gdata.vision.transforms.Normalize(train_mean, train_std)]\n",
    "transformer = gdata.vision.transforms.Compose(transformer)\n",
    "num_workers = 0 if sys.platform.startswith('win32') else 4\n",
    "\n",
    "train_iter = gdata.DataLoader(train_dataset.transform_first(transformer), batch_size = batch_size, shuffle=True, num_workers=num_workers)\n",
    "valid_iter = gdata.DataLoader(valid_dataset.transform_first(transformer), batch_size = batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_iter = gdata.DataLoader(test_dataset.transform_first(transformer), batch_size = batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "extra_transformer = []\n",
    "extra_transformer += [gdata.vision.transforms.ToTensor()] # transer the train data from shape (sample, H, W, channel) to (sample, channel, H, W) and rescale to between 0 and 1 \n",
    "extra_transformer += [gdata.vision.transforms.Normalize(extra_validation_mean, extra_validation_std)]\n",
    "extra_transformer = gdata.vision.transforms.Compose(extra_transformer)\n",
    "extra_validation_iter = gdata.DataLoader(extra_validation_dataset.transform_first(extra_transformer), batch_size = batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu():\n",
    "    \"\"\"If GPU is available, return mx.gpu(0); else return mx.cpu().\"\"\"\n",
    "    try:\n",
    "        ctx = mx.gpu()\n",
    "        _ = nd.array([0], ctx=ctx)\n",
    "    except mx.base.MXNetError:\n",
    "        ctx = mx.cpu()\n",
    "    return ctx\n",
    "def evaluate_accuracy(data_iter, net, ctx=[mx.cpu()]):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    acc_sum, n = nd.array([0]), 0\n",
    "    for batch in data_iter:\n",
    "        features, labels, _ = _get_batch(batch, ctx)\n",
    "        for X, y in zip(features, labels):\n",
    "            y = y.astype('float32')\n",
    "            acc_sum += (net(X).argmax(axis=1) == y).sum().copyto(mx.cpu())\n",
    "            n += y.size\n",
    "        acc_sum.wait_to_read()\n",
    "    return acc_sum.asscalar() / n\n",
    "\n",
    "def _get_batch(batch, ctx):\n",
    "    \"\"\"Return features and labels on ctx.\"\"\"\n",
    "    features, labels = batch\n",
    "    if labels.dtype != features.dtype:\n",
    "        labels = labels.astype(features.dtype)\n",
    "    return (gutils.split_and_load(features, ctx),\n",
    "            gutils.split_and_load(labels, ctx), features.shape[0])\n",
    "\n",
    "def train(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs):\n",
    "    \"\"\"Train and evaluate a model with CPU or GPU.\"\"\"\n",
    "    print('training on', ctx)\n",
    "    loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "    average_time = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                y_hat = net(X)            \n",
    "                l = loss(y_hat, y).sum()\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            y = y.astype('float32')\n",
    "            train_l_sum += l.asscalar()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n",
    "            n += y.size\n",
    "        \n",
    "        test_acc = evaluate_accuracy(test_iter, net, ctx)\n",
    "        epoch_time = time.time() - start\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc, epoch_time))\n",
    "        average_time += epoch_time\n",
    "    print('Average time per epoch is %.4f s.'%(average_time/num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = try_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESNET-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Block):\n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1, **kwargs):\n",
    "        super(Residual, self).__init__(**kwargs) \n",
    "        self.conv1 = nn.Conv2D(num_channels, kernel_size=3, padding=1, strides=strides) # this layer down-sampling the input\n",
    "        self.conv2 = nn.Conv2D(num_channels, kernel_size=3, padding=1)  # the layer doesn't down-sampling the input\n",
    "        \n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2D(num_channels, kernel_size=1, strides=strides)\n",
    "            # to match the dimension of feature map of conv1 + conv2, the strides must be set to be identicla to conv 1\n",
    "        else: \n",
    "            self.conv3 = None \n",
    "            \n",
    "        self.bn1 = nn.BatchNorm() \n",
    "        self.bn2 = nn.BatchNorm()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        Y = nd.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y)) \n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "\n",
    "        return nd.relu(Y + X)\n",
    "    \n",
    "def resnet_block(num_channels, num_residuals, first_block=False): \n",
    "    blk = nn.Sequential() \n",
    "    for i in range(num_residuals): \n",
    "        if i == 0 and not first_block:\n",
    "            #net.add(Residual(num_channels, use_1x1conv=True, strides=2))\n",
    "            blk.add(Residual(num_channels, use_1x1conv=True, strides=2))\n",
    "        else:\n",
    "            #net.add(Residual(num_channels, strides=1))\n",
    "            blk.add(Residual(num_channels, strides=1))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_output_channels = [64, 128, 256, 512]\n",
    "num_residuals = 2\n",
    "\n",
    "net_RESNET = nn.Sequential() \n",
    "net_RESNET.add(nn.Conv2D(64, kernel_size=7, strides=2, padding=3),\n",
    "        nn.BatchNorm(), \n",
    "        nn.Activation('relu'),\n",
    "        nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n",
    "\n",
    "for i, num in enumerate(num_of_output_channels):\n",
    "    if i==0:\n",
    "        net_RESNET.add(resnet_block(num, num_residuals, first_block=True))\n",
    "    else:\n",
    "        net_RESNET.add(resnet_block(num, num_residuals))\n",
    "    net_RESNET.add(nn.Dropout(0.1))\n",
    "\n",
    "net_RESNET.add(nn.GlobalAvgPool2D(), nn.Dense(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize or Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_RESNET.load_parameters('Weight_Train_Test_Mixed/RESNET18_DROPOUT_train_data_transposed_2.params', ctx= ctx)\n",
    "#net_RESNET.initialize(ctx=ctx, init=mx.init.Xavier(rnd_type ='gaussian', factor_type='in', magnitude=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "        Layer (type)                                Output Shape         Param #\n",
      "================================================================================\n",
      "               Input                           (64, 3, 256, 256)               0\n",
      "            Conv2D-1                          (64, 64, 128, 128)            9472\n",
      "         BatchNorm-2                          (64, 64, 128, 128)             256\n",
      "        Activation-3                          (64, 64, 128, 128)               0\n",
      "         MaxPool2D-4                            (64, 64, 64, 64)               0\n",
      "            Conv2D-5                            (64, 64, 64, 64)           36928\n",
      "         BatchNorm-6                            (64, 64, 64, 64)             256\n",
      "            Conv2D-7                            (64, 64, 64, 64)           36928\n",
      "         BatchNorm-8                            (64, 64, 64, 64)             256\n",
      "          Residual-9                            (64, 64, 64, 64)               0\n",
      "           Conv2D-10                            (64, 64, 64, 64)           36928\n",
      "        BatchNorm-11                            (64, 64, 64, 64)             256\n",
      "           Conv2D-12                            (64, 64, 64, 64)           36928\n",
      "        BatchNorm-13                            (64, 64, 64, 64)             256\n",
      "         Residual-14                            (64, 64, 64, 64)               0\n",
      "          Dropout-15                            (64, 64, 64, 64)               0\n",
      "           Conv2D-16                           (64, 128, 32, 32)           73856\n",
      "        BatchNorm-17                           (64, 128, 32, 32)             512\n",
      "           Conv2D-18                           (64, 128, 32, 32)          147584\n",
      "        BatchNorm-19                           (64, 128, 32, 32)             512\n",
      "           Conv2D-20                           (64, 128, 32, 32)            8320\n",
      "         Residual-21                           (64, 128, 32, 32)               0\n",
      "           Conv2D-22                           (64, 128, 32, 32)          147584\n",
      "        BatchNorm-23                           (64, 128, 32, 32)             512\n",
      "           Conv2D-24                           (64, 128, 32, 32)          147584\n",
      "        BatchNorm-25                           (64, 128, 32, 32)             512\n",
      "         Residual-26                           (64, 128, 32, 32)               0\n",
      "          Dropout-27                           (64, 128, 32, 32)               0\n",
      "           Conv2D-28                           (64, 256, 16, 16)          295168\n",
      "        BatchNorm-29                           (64, 256, 16, 16)            1024\n",
      "           Conv2D-30                           (64, 256, 16, 16)          590080\n",
      "        BatchNorm-31                           (64, 256, 16, 16)            1024\n",
      "           Conv2D-32                           (64, 256, 16, 16)           33024\n",
      "         Residual-33                           (64, 256, 16, 16)               0\n",
      "           Conv2D-34                           (64, 256, 16, 16)          590080\n",
      "        BatchNorm-35                           (64, 256, 16, 16)            1024\n",
      "           Conv2D-36                           (64, 256, 16, 16)          590080\n",
      "        BatchNorm-37                           (64, 256, 16, 16)            1024\n",
      "         Residual-38                           (64, 256, 16, 16)               0\n",
      "          Dropout-39                           (64, 256, 16, 16)               0\n",
      "           Conv2D-40                             (64, 512, 8, 8)         1180160\n",
      "        BatchNorm-41                             (64, 512, 8, 8)            2048\n",
      "           Conv2D-42                             (64, 512, 8, 8)         2359808\n",
      "        BatchNorm-43                             (64, 512, 8, 8)            2048\n",
      "           Conv2D-44                             (64, 512, 8, 8)          131584\n",
      "         Residual-45                             (64, 512, 8, 8)               0\n",
      "           Conv2D-46                             (64, 512, 8, 8)         2359808\n",
      "        BatchNorm-47                             (64, 512, 8, 8)            2048\n",
      "           Conv2D-48                             (64, 512, 8, 8)         2359808\n",
      "        BatchNorm-49                             (64, 512, 8, 8)            2048\n",
      "         Residual-50                             (64, 512, 8, 8)               0\n",
      "          Dropout-51                             (64, 512, 8, 8)               0\n",
      "  GlobalAvgPool2D-52                             (64, 512, 1, 1)               0\n",
      "            Dense-53                                     (64, 6)            3078\n",
      "================================================================================\n",
      "Parameters in forward computation graph, duplicate included\n",
      "   Total params: 11190406\n",
      "   Trainable params: 11182598\n",
      "   Non-trainable params: 7808\n",
      "Shared params in forward computation graph: 0\n",
      "Unique parameters in model: 11190406\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for X,_ in train_iter:\n",
    "    net_RESNET.summary(X.as_in_context(ctx))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optimizer = mx.optimizer.Adam(learning_rate=1e-4, beta1=0.9, beta2=0.9)\n",
    "trainer = gluon.Trainer(net_RESNET.collect_params(), optimizer=adam_optimizer)\n",
    "train(net_RESNET, train_iter, valid_iter, batch_size, trainer, ctx, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Accuracy for Testing Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model is 89.6667 % .\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of model is %.4f %% .'%(100*evaluate_accuracy(test_iter, net_RESNET, ctx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Accuracy for Extra Validation Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model is 64.2857 % .\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of model is %.4f %% .'%(100*evaluate_accuracy(extra_validation_iter, net_RESNET, ctx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Saving and Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net_RESNET.save_parameters('C:/Users/lab/Jupyter_Notebook/Guan-Ming/Midterm_Project/NN_params/train_test_mixed/RESNET18_DROPOUT_train_data_transposed.params')\n",
    "#net_RESNET.save_parameters('C:/Users/lab/Jupyter_Notebook/Guan-Ming/Midterm_Project/NN_params/train_test_mixed/RESNET18_DROPOUT_train_data_transposed_2.params')\n",
    "#===============================================================\n",
    "# num_jitter = 2\n",
    "# color_aug = gdata.vision.transforms.RandomColorJitter(brightness=0.4, contrast=0.3)\n",
    "#===============================================================\n",
    "# num_of_output_channels = [64, 128, 256, 512]\n",
    "# num_residuals = 2\n",
    "\n",
    "# net_RESNET = nn.Sequential() \n",
    "# net_RESNET.add(nn.Conv2D(64, kernel_size=7, strides=2, padding=3),\n",
    "#         nn.BatchNorm(), \n",
    "#         nn.Activation('relu'),\n",
    "#         nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n",
    "\n",
    "# for i, num in enumerate(num_of_output_channels):\n",
    "#     if i==0:\n",
    "#         net_RESNET.add(resnet_block(num, num_residuals, first_block=True))\n",
    "#     else:\n",
    "#         net_RESNET.add(resnet_block(num, num_residuals))\n",
    "#     net_RESNET.add(nn.Dropout(0.1))\n",
    "\n",
    "# net_RESNET.add(nn.GlobalAvgPool2D(), nn.Dense(6))\n",
    "#==============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix of Testing Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = np.zeros(total_test_data)\n",
    "count = 0\n",
    "for X, _ in test_iter:\n",
    "    y_pred_test[count:min(count+batch_size, total_test_data)] = net_RESNET(X.as_in_context(ctx)).asnumpy().argmax(axis=1)\n",
    "    count += batch_size\n",
    "wrong_index_test = np.argwhere(y_pred_test!=test_data_y.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47  3  0  0  0  0]\n",
      " [ 1 48  1  0  0  0]\n",
      " [ 0  0 48  2  0  0]\n",
      " [ 2  0  1 45  2  0]\n",
      " [ 3  0  6  1 40  0]\n",
      " [ 2  0  6  0  1 41]]\n",
      "\n",
      "\n",
      "Accuracy of 0 is 94.00 %.\n",
      "Accuracy of 1 is 96.00 %.\n",
      "Accuracy of 2 is 96.00 %.\n",
      "Accuracy of 3 is 90.00 %.\n",
      "Accuracy of 4 is 80.00 %.\n",
      "Accuracy of 5 is 82.00 %.\n"
     ]
    }
   ],
   "source": [
    "result = confusion_matrix(test_data_y.asnumpy(), y_pred_test)\n",
    "print(result)\n",
    "print('\\n')\n",
    "for i in range(6):\n",
    "    print(\"Accuracy of %d is %.2f %%.\" %(i, 100*result[i][i]/result[i].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 31 wrong predcition. Slide to see the corresponding image.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54dcb71ad3f4636becdc19eef0a0b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index_selected', max=30), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def PLOT_WRONG_PREDICTION(index_selected):\n",
    "    print(index_selected)\n",
    "    plt.figure(figsize=(3,3), dpi=120)\n",
    "    plt.imshow(test_data_x[wrong_index_test[index_selected]][0].asnumpy().astype(np.uint8))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"NN Recognizes as %d .\\nReal Answer is %d .\" %(y_pred_test[wrong_index_test[index_selected]], test_data_y[wrong_index_test[index_selected]].asscalar()) )\n",
    "    \n",
    "print('Total %d wrong predcition. Slide to see the corresponding image.' %len(wrong_index_test))\n",
    "interact(PLOT_WRONG_PREDICTION, index_selected=IntSlider(value=0, min=0, max=len(wrong_index_test)-1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix of Extra Validation Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_extra_validation = np.zeros(total_extra_validation_data)\n",
    "count = 0\n",
    "for X, _ in extra_validation_iter:\n",
    "    y_pred_extra_validation[count:count+batch_size] = net_RESNET(X.as_in_context(ctx))[:total_extra_validation_data].asnumpy().argmax(axis=1)\n",
    "    count += batch_size\n",
    "wrong_index_extra_validation = np.argwhere(y_pred_extra_validation!=extra_validation_data_y.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  0  0  0  0  0]\n",
      " [ 0  3  2  1  0  0]\n",
      " [ 0  1  3  2  0  0]\n",
      " [ 0  4  2 16  3  2]\n",
      " [ 0  0  0  2  3  0]\n",
      " [ 0  0  0  1  0  9]]\n",
      "\n",
      "\n",
      "Accuracy of 0 is 100.00 %.\n",
      "Accuracy of 1 is 50.00 %.\n",
      "Accuracy of 2 is 50.00 %.\n",
      "Accuracy of 3 is 59.26 %.\n",
      "Accuracy of 4 is 60.00 %.\n",
      "Accuracy of 5 is 90.00 %.\n"
     ]
    }
   ],
   "source": [
    "result = confusion_matrix(extra_validation_data_y.asnumpy(), y_pred_extra_validation)\n",
    "print(result)\n",
    "print('\\n')\n",
    "for i in range(6):\n",
    "    print(\"Accuracy of %d is %.2f %%.\" %(i, 100*result[i][i]/result[i].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 20 wrong predcition. Slide to see the corresponding image.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872521e25dbf4c9c973c8a56409fed47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index_selected', max=19), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def PLOT_WRONG_PREDICTION(index_selected):\n",
    "    print(index_selected)\n",
    "    plt.figure(figsize=(3,3), dpi=120)\n",
    "    plt.imshow(extra_validation_data_x[wrong_index_extra_validation[index_selected]][0].asnumpy().astype(np.uint8))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"NN Recognizes as %d .\\nReal Answer is %d .\" %(y_pred_extra_validation[wrong_index_extra_validation[index_selected]], extra_validation_data_y[wrong_index_extra_validation[index_selected]].asscalar()) )\n",
    "    \n",
    "print('Total %d wrong predcition. Slide to see the corresponding image.' %len(wrong_index_extra_validation))\n",
    "interact(PLOT_WRONG_PREDICTION, index_selected=IntSlider(value=0, min=0, max=len(wrong_index_extra_validation)-1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
